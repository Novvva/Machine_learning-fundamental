{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# prepare the data\n",
    "bc = datasets.load_breast_cancer()\n",
    "X,y = bc.data, bc.target\n",
    "\n",
    "n_samples,n_features = X.shape\n",
    "print(n_samples)\n",
    "print(n_features)\n",
    "\n",
    "X_train, X_test,y_train,y_test = train_test_split(X,y, test_size = 0.2, random_state = 1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the function.\n",
    "# preprocess the data.\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "y_train = y_train.view(y_train.shape[0],1)\n",
    "y_test = y_test.view(y_test.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "class LogisticRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self,n_input_features):\n",
    "        super(LogisticRegression,self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        y_predicted = torch.sigmoid(self.linear(x))\n",
    "        return y_predicted\n",
    "\n",
    "model = LogisticRegression(n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10,loss = 0.7033\n",
      "epoch:20,loss = 0.5492\n",
      "epoch:30,loss = 0.4573\n",
      "epoch:40,loss = 0.3970\n",
      "epoch:50,loss = 0.3544\n",
      "epoch:60,loss = 0.3226\n",
      "epoch:70,loss = 0.2979\n",
      "epoch:80,loss = 0.2781\n",
      "epoch:90,loss = 0.2618\n",
      "epoch:100,loss = 0.2481\n"
     ]
    }
   ],
   "source": [
    "# Training the data.\n",
    "\n",
    "learning_rate = 0.01\n",
    "criterion = nn.BCELoss()    # Binary entropy\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = learning_rate)\n",
    "\n",
    "# Training loop\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # Train data\n",
    "    y_predicted = model(X_train)\n",
    "    loss = criterion(y_predicted,y_train)\n",
    "    \n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    #update\n",
    "    optimizer.step()\n",
    "    \n",
    "    #zero gradients because the backward will add up the gradient \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch+1)%10 ==0:\n",
    "        print(f'epoch:{epoch+1},loss = {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9474\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_predicted = model(X_test)\n",
    "    y_predicted_cls = y_predicted.round()\n",
    "    \n",
    "    acc = y_predicted_cls.eq(y_test).sum()/float(y_test.shape[0])\n",
    "    print(f'accuracy = {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.loadtxt('https://raw.githubusercontent.com/python-engineer/pytorchTutorial/master/data/wine/wine.csv',delimiter = \",\",dtype = np.float32, skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 14)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03]), tensor([1.]))\n"
     ]
    }
   ],
   "source": [
    "## New tutorial\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np \n",
    "import math\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # data loading\n",
    "        xy = np.loadtxt('https://raw.githubusercontent.com/python-engineer/pytorchTutorial/master/data/wine/wine.csv',delimiter = \",\",dtype = np.float32, skiprows = 1)\n",
    "        self.x = torch.from_numpy(xy[:,1:])\n",
    "        self.y = torch.from_numpy(xy[:,[0]])   # n_samples,1\n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        # dataset[0]\n",
    "        return self.x[index],self.y[index]\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        # len(dataset)\n",
    "        return self.n_samples\n",
    "    \n",
    "dataset = WineDataset()\n",
    "first_data = dataset[0]\n",
    "features,labels = first_data\n",
    "print(first_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2000e+01, 1.5100e+00, 2.4200e+00, 2.2000e+01, 8.6000e+01, 1.4500e+00,\n",
      "         1.2500e+00, 5.0000e-01, 1.6300e+00, 3.6000e+00, 1.0500e+00, 2.6500e+00,\n",
      "         4.5000e+02],\n",
      "        [1.2000e+01, 3.4300e+00, 2.0000e+00, 1.9000e+01, 8.7000e+01, 2.0000e+00,\n",
      "         1.6400e+00, 3.7000e-01, 1.8700e+00, 1.2800e+00, 9.3000e-01, 3.0500e+00,\n",
      "         5.6400e+02],\n",
      "        [1.3160e+01, 3.5700e+00, 2.1500e+00, 2.1000e+01, 1.0200e+02, 1.5000e+00,\n",
      "         5.5000e-01, 4.3000e-01, 1.3000e+00, 4.0000e+00, 6.0000e-01, 1.6800e+00,\n",
      "         8.3000e+02],\n",
      "        [1.2250e+01, 4.7200e+00, 2.5400e+00, 2.1000e+01, 8.9000e+01, 1.3800e+00,\n",
      "         4.7000e-01, 5.3000e-01, 8.0000e-01, 3.8500e+00, 7.5000e-01, 1.2700e+00,\n",
      "         7.2000e+02]]) tensor([[2.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [3.]])\n",
      "178 45\n",
      "epoch1/2,step 5/45,input torch.Size([4, 13])\n",
      "epoch1/2,step 10/45,input torch.Size([4, 13])\n",
      "epoch1/2,step 15/45,input torch.Size([4, 13])\n",
      "epoch1/2,step 20/45,input torch.Size([4, 13])\n",
      "epoch1/2,step 25/45,input torch.Size([4, 13])\n",
      "epoch1/2,step 30/45,input torch.Size([4, 13])\n",
      "epoch1/2,step 35/45,input torch.Size([4, 13])\n",
      "epoch1/2,step 40/45,input torch.Size([4, 13])\n",
      "epoch1/2,step 45/45,input torch.Size([2, 13])\n",
      "epoch2/2,step 5/45,input torch.Size([4, 13])\n",
      "epoch2/2,step 10/45,input torch.Size([4, 13])\n",
      "epoch2/2,step 15/45,input torch.Size([4, 13])\n",
      "epoch2/2,step 20/45,input torch.Size([4, 13])\n",
      "epoch2/2,step 25/45,input torch.Size([4, 13])\n",
      "epoch2/2,step 30/45,input torch.Size([4, 13])\n",
      "epoch2/2,step 35/45,input torch.Size([4, 13])\n",
      "epoch2/2,step 40/45,input torch.Size([4, 13])\n",
      "epoch2/2,step 45/45,input torch.Size([2, 13])\n"
     ]
    }
   ],
   "source": [
    "dataset = WineDataset()\n",
    "dataloader = DataLoader(dataset = dataset, batch_size = 4, shuffle = True, num_workers = 0)\n",
    "\n",
    "datatiter = iter(dataloader)\n",
    "data = datatiter.next()\n",
    "features, labels = data\n",
    "print(features,labels)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 2\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples/4)\n",
    "print(total_samples,n_iterations)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs,labels) in enumerate(dataloader):\n",
    "        # forward backward , update our weights\n",
    "        if (i+1) % 5 == 0:\n",
    "            print(f'epoch{epoch+1}/{num_epochs},step {i+1}/{n_iterations},input {inputs.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New tutorial on dataset transformation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.ToTensor object at 0x0000021DD4ADD0C8>\n",
      "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03]) <class 'torch.Tensor'>\n",
      "Compose(\n",
      "    <__main__.MulTransform object at 0x0000021DD4B64288>\n",
      "    <__main__.ToTensor object at 0x0000021DC68525C8>\n",
      ")\n",
      "tensor([2.8460e+01, 3.4200e+00, 4.8600e+00, 3.1200e+01, 2.5400e+02, 5.6000e+00,\n",
      "        6.1200e+00, 5.6000e-01, 4.5800e+00, 1.1280e+01, 2.0800e+00, 7.8400e+00,\n",
      "        2.1300e+03]) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# We need to transform the data into tensor set.  from tensor or ndarray to imagine for example.\n",
    "import torch \n",
    "import torchvision\n",
    "\n",
    "# Impelment the transoform feature.\n",
    "class WineDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,transform = None):\n",
    "        # data loading\n",
    "        xy = np.loadtxt('https://raw.githubusercontent.com/python-engineer/pytorchTutorial/master/data/wine/wine.csv',delimiter = \",\",dtype = np.float32, skiprows = 1)\n",
    "        self.x = xy[:,1:]  # numpy array\n",
    "        self.y = xy[:,[0]]   # n_samples,1\n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        # dataset[0]\n",
    "        sample = self.x[index],self.y[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            print(self.transform)\n",
    "            sample = self.transform(sample)\n",
    "                    \n",
    "        return sample\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        # len(dataset)\n",
    "        return self.n_samples\n",
    "    \n",
    "    \n",
    "class ToTensor:\n",
    "    \n",
    "    #Callable object\n",
    "    def __call__(self,sample):\n",
    "        inputs, target = sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(target)\n",
    "    \n",
    "class MulTransform:\n",
    "    def __init__(self,factor):\n",
    "        self.factor = factor\n",
    "        \n",
    "    def __call__(self,sample):\n",
    "        inputs, target = sample\n",
    "        inputs *= self.factor\n",
    "        return inputs,target\n",
    "    \n",
    "dataset = WineDataset(transform = ToTensor())\n",
    "first_data = dataset[0]\n",
    "feature,labels = first_data\n",
    "\n",
    "print(feature,type(labels))\n",
    "\n",
    "composed = torchvision.transforms.Compose({ToTensor(),MulTransform(2)})\n",
    "dataset =  WineDataset(transform = composed)\n",
    "first_data = dataset[0]\n",
    "feature,labels = first_data\n",
    "print(feature,type(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
       "         3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
       "         1.0650e+03]),\n",
       " tensor([1.]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax numpy: [0.65900114 0.24243297 0.09856589]\n",
      "tensor([0.6590, 0.2424, 0.0986])\n",
      "0.35667494393873245 2.3025850929940455\n",
      "0.38459011912345886 1.1199532747268677\n",
      "tensor([2, 0, 1]) tensor([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Softmax layer [ Tranform the output into probably list].\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x)/ np.sum(np.exp(x),axis=0)\n",
    "\n",
    "x = np.array([2.0,1.0,0.1])\n",
    "outputs = softmax(x)\n",
    "print('softmax numpy:', outputs)\n",
    "\n",
    "x = torch.tensor([2.0,1.0,0.1])\n",
    "outputs = torch.softmax(x,dim =0)\n",
    "print(outputs)\n",
    "\n",
    "# Cross-Entropy loss: information loss. : note Y has to be one-hot encoded. \n",
    "\n",
    "\n",
    "def cross_entropy(actual,predicted):\n",
    "    loss = -np.sum(actual * np.log(predicted))  \n",
    "    return loss\n",
    "\n",
    "Y = np.array([1,0,0])\n",
    "\n",
    "Y_pred_good = np.array([0.7,0.2,0.1])\n",
    "Y_pred_bad  = np.array([0.1,0.3,0.6])\n",
    "l1 = cross_entropy(Y,Y_pred_good)\n",
    "l2 = cross_entropy(Y,Y_pred_bad)\n",
    "print(l1,l2)\n",
    "\n",
    "# Pytorch implmentation\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# Careful: nn.CrossEntropyLoss applies: nn.LogSoftmax + nn.NLLLoss.  So No Softmax in last layer\n",
    "# Y has class labels, not One-Hot!\n",
    "# Y_predict has raws scores, no Softmax\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "Y = torch.tensor([2,0,1])\n",
    "# nsamples * nclasss = 3x3. lets say we have 3 samples\n",
    "\n",
    "Y_pred_good = torch.tensor([[0.1,1.0,2.1],\n",
    "                           [2.0,1.0,0.1],\n",
    "                           [2.0,3.0,0.1]])\n",
    "\n",
    "Y_pred_bad = torch.tensor([[0.1,0.3,0.6],\n",
    "                           [0.1,0.3,0.6],\n",
    "                           [0.1,0.3,0.6]\n",
    "                          ])\n",
    "\n",
    "l1 = loss(Y_pred_good,Y)\n",
    "l2 = loss(Y_pred_bad,Y)\n",
    "print(l1.item(),l2.item())\n",
    "\n",
    "_,prediction1 = torch.max(Y_pred_good,1)\n",
    "_,prediction2 = torch.max(Y_pred_bad,1)\n",
    "print(prediction1, prediction2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiclass problem\n",
    "\n",
    "class NeuralNet2(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_size,hidden_size,num_classes):\n",
    "        super(NeuralNet2,self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size,hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        return out \n",
    "        \n",
    "model = NeuralNet2(input_size = 28*28, hidden_size = 5, num_classes = 3)\n",
    "criterion = nn.CrossEntropyLoss()   #apply softmax!!!!!!!!!!!\n",
    "\n",
    "## if sigmoid function, we could just use nn.BCELoss() [ Binary cross-entropy loss, but we have to implement a sigmoid function at the end]\n",
    "\n",
    "class NeuralNet3(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_size,hidden_size,num_classes):\n",
    "        super(NeuralNet2,self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size,hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        \n",
    "        # sigmoid at the end here\n",
    "        y_pred = torch.sigmoid(out)\n",
    "        return y_pred\n",
    "        \n",
    "model = NeuralNet2(input_size = 28*28, hidden_size = 5, num_classes = 3)\n",
    "criterion = nn.CrossEntropyLoss()   #apply softmax!!!!!!!!!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation fucntion. we need to use an activation function [ Relu for example.]\n",
    "# Step Function,Sigmoid Function(Typically in the last layer of a binary classification problem),\n",
    "# TanH Function [scaled sigmodi Function], ReLu Function [mostly used.]\n",
    "# Leaky ReLu Function for solving the gradient vanishing problem. We need to set up the a.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/ 2, step  100/600, loss = 0.5101\n",
      "epoch 1/ 2, step  200/600, loss = 0.3987\n",
      "epoch 1/ 2, step  300/600, loss = 0.3490\n",
      "epoch 1/ 2, step  400/600, loss = 0.2441\n",
      "epoch 1/ 2, step  500/600, loss = 0.2226\n",
      "epoch 1/ 2, step  600/600, loss = 0.1910\n",
      "epoch 2/ 2, step  100/600, loss = 0.2192\n",
      "epoch 2/ 2, step  200/600, loss = 0.1517\n",
      "epoch 2/ 2, step  300/600, loss = 0.2688\n",
      "epoch 2/ 2, step  400/600, loss = 0.1887\n",
      "epoch 2/ 2, step  500/600, loss = 0.1849\n",
      "epoch 2/ 2, step  600/600, loss = 0.2001\n",
      "accuracy = 95.23\n"
     ]
    }
   ],
   "source": [
    "# Toy example. \n",
    "\n",
    "# MNIST\n",
    "# DatLoader, Transformation\n",
    "# Multilayer Neural Net, activiation function\n",
    "# Loss and Optimzier \n",
    "# Traning Loop (batch training)\n",
    "# Model evaluation\n",
    "# GPU support.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# device configuration\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# hyper parameters\n",
    "input_size = 784 # 28* 28\n",
    "hidden_size = 100\n",
    "num_classes = 10 # 10 different digit\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST DATA\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root = './data',train = True, transform = transforms.ToTensor(),download = True)\n",
    "test_dataset = torchvision.datasets.MNIST(root = './data',train = False, transform = transforms.ToTensor(),download = True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "examples = iter(train_loader)\n",
    "samples, labels = examples.next()\n",
    "print(samples.shape, labels.shape)\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(samples[i][0],cmap= 'gray')\n",
    "plt.show()\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self,input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet,self).__init__()\n",
    "        self.l1 =nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        # we use cross-entropy losss\n",
    "        return out\n",
    "    \n",
    "model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "# loss and optimizer\n",
    " \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\n",
    "\n",
    "# training loop\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        # 100,1,28,28\n",
    "        # iunput size should be 100,784  # -1 by defaut, 28*28 is the second dimension  \n",
    "        images = images.reshape(-1,28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()   # back-propogation\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'epoch {epoch+1}/ {num_epochs}, step  {i+1}/{n_total_steps}, loss = {loss.item():.4f}')\n",
    "\n",
    "# Testing the performance\n",
    "\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1,28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # return value,index \n",
    "        _, predictions = torch.max(outputs,1)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "        \n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'accuracy = {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4],Step [2000/12500],Loss: 2.2710\n",
      "Epoch [1/4],Step [4000/12500],Loss: 2.3052\n",
      "Epoch [1/4],Step [6000/12500],Loss: 2.2900\n",
      "Epoch [1/4],Step [8000/12500],Loss: 2.2324\n",
      "Epoch [1/4],Step [10000/12500],Loss: 2.1602\n",
      "Epoch [1/4],Step [12000/12500],Loss: 3.0008\n",
      "Epoch [2/4],Step [2000/12500],Loss: 2.0717\n",
      "Epoch [2/4],Step [4000/12500],Loss: 1.5620\n",
      "Epoch [2/4],Step [6000/12500],Loss: 1.9453\n",
      "Epoch [2/4],Step [8000/12500],Loss: 2.4279\n",
      "Epoch [2/4],Step [10000/12500],Loss: 1.6791\n",
      "Epoch [2/4],Step [12000/12500],Loss: 1.3932\n",
      "Epoch [3/4],Step [2000/12500],Loss: 1.7579\n",
      "Epoch [3/4],Step [4000/12500],Loss: 1.5374\n",
      "Epoch [3/4],Step [6000/12500],Loss: 1.5899\n",
      "Epoch [3/4],Step [8000/12500],Loss: 1.6400\n",
      "Epoch [3/4],Step [10000/12500],Loss: 1.1611\n",
      "Epoch [3/4],Step [12000/12500],Loss: 1.2393\n",
      "Epoch [4/4],Step [2000/12500],Loss: 1.5876\n",
      "Epoch [4/4],Step [4000/12500],Loss: 1.1922\n",
      "Epoch [4/4],Step [6000/12500],Loss: 0.9158\n",
      "Epoch [4/4],Step [8000/12500],Loss: 1.6364\n",
      "Epoch [4/4],Step [10000/12500],Loss: 0.8428\n",
      "Epoch [4/4],Step [12000/12500],Loss: 1.6637\n",
      "Finished Training\n",
      "Accuracy of the network: 45.47 %\n"
     ]
    }
   ],
   "source": [
    "## CNN tutorail implementation : Imagine classification\n",
    "# CNN clasify the imagines.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# Hyper-parmeters\n",
    "num_epochs = 4\n",
    "batch_size = 4\n",
    "learning_rate = 0.001\n",
    "\n",
    "# dataset has PILImagine image of range[0,1]. \n",
    "# We transform them to Tensors of normalized range [-1,1]\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root = './data',train = True,download = False,transform = transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root = './data',train = False,download = False,transform = transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size ,shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "# hardcode the class\n",
    "classes = ('plane','car','bird','cat','deer','dog','frog','horse','ship','truck')\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,6,5)     # Dimension.\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1,16*5*5)   # flat our tensor\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "         \n",
    "\n",
    "model = ConvNet().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = learning_rate)\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # original shape: [4,3,32,32] = 4,3,1024\n",
    "        # input_layer: 3 input channels, 6 output channels, 5 kernel size.\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1)% 2000 == 0:\n",
    "            print( f'Epoch [{epoch+1}/{num_epochs}],Step [{i+1}/{n_total_steps}],Loss: {loss.item():.4f}')\n",
    "    \n",
    "print('Finished Training')\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    n_correct = 0\n",
    "    n_sample = 0\n",
    "    n_class_correct = [0 for i in range(10)]\n",
    "    n_class_samples = [0 for i in range(10)]\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # max returns(value, index)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_sample += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] +=1\n",
    "            n_class_samples[label] +=1\n",
    "            \n",
    "    acc = 100.0 * n_correct / n_sample\n",
    "    print(f'Accuracy of the network: {acc} %')\n",
    "\n",
    "# This is not very good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfirm learning. \n",
    "# ImageineFolder\n",
    "# Scheduler\n",
    "# Transfer learning\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pylot as plt\n",
    "import time \n",
    "import os \n",
    "import copy\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "mean = np.array([0.485,0.456,0.406])\n",
    "std = np.array([0.229,0.224,0.225])\n",
    "\n",
    "data_transforms = {'train': transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std)\n",
    "]),\n",
    "                  'val': transforms.Compose([\n",
    "                      transforms.Resize(256),\n",
    "                      transforms.CenterCrop(224),\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Normalize(mean,std)\n",
    "                  ])}\n",
    "\n",
    "\n",
    "# import data\n",
    "data_dir = 'data/hymenoptera_data'\n",
    "sets = ['train','val']\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir,x),\n",
    "                                         data_transforms[x]) for x in ['train','val']}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],batch_size = 4,shuffle = True, num_workers = 0) for i in ['train','val']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train','val']}\n",
    "class_names = image_datsets['train'].classes\n",
    "print(class_names)\n",
    "\n",
    "def train_model(model,criterion, optimizer, scheduler, num_epochs = 25):\n",
    "    since = time.time()\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs -1}')\n",
    "        print('-'*10)\n",
    "        \n",
    "        # Each epoch has a training and a validation phase'\n",
    "        for phase in ['train','val']:\n",
    "            if phase = 'train':\n",
    "                model.train()   # set model to training mode\n",
    "            else:\n",
    "                model.eval()    # Set model to evaluate mode\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "        # Iterate over data. \n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # forward\n",
    "            # track history in only in train\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # backward+ optimize only if in training phase\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds = labels.data)\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            \n",
    "            epoch_loss = running_loss/ dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_size[phase]\n",
    "            \n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "            print()\n",
    "            \n",
    "        \n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed//60:.0f}m {time_elapsed%60:.0f}s')\n",
    "        \n",
    "        # load besty model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "        return model\n",
    "    \n",
    "    \n",
    "model = models.resnet18(pretrained = True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "      \n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "\n",
    "model.fc = nn.Linear(num_ftrs, 2)          # we only have two classes\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001)\n",
    "\n",
    "# scheduler \n",
    "# update the learning rate. \n",
    "\n",
    "step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)      # every 7 epoch, our learning rate is multiply by gamma.\n",
    "for epoch in range(100):\n",
    "    train()   # optimizer.step()\n",
    "    evaluate()\n",
    "    scheduler.step()\n",
    "    \n",
    "\n",
    "model = train_model(model, criterion, optimizer, scheduler, num_epochs = 20)\n",
    "                    \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
